---
title: Generative AI with LLMs
draft: true
date: "281120232114"
tags:
  - course
  - work_in_progress
related:
  - "[[Generative AI]]"
---
# Generative AI with LLMs - Coursera course
## Links
- [Coursera page](https://www.coursera.org/learn/generative-ai-with-llms/)
---

## Week 1: Introduction to LLMs and generative AI project lifecycle
- Smaller models (1B-30B parameters) work well for single use cases, while bigger models are useful to generalize to multiple tasks.
- [[Generative AI]] and [[Large Language Models|LLMs]] use cases
	- Relation between model's parameters number and its "memory" and performance.
	- Definitions
		- **Prompt**: text that is passed to an LLM.
		- **Context window**: the space, or memory that is available to the prompt.
		- **Completion**: output of the model during inference.

## Week 2: Fine-tuning LLMs with instruction

## Week 3: Reinforcement Learning from Human Feedback ([[Reinforcement Learning from Human Feedback|RLHF]])

---
# References
- 